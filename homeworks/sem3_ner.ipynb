{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 3  NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:\n",
    "\n",
    "Реализуйте 2 функции препроцессинга:\n",
    "\n",
    "- Удалить именованные сущности с помощью natasha (https://github.com/natasha/yargy)\n",
    "- Удалить именованные сущности с помощью deepmipt (https://github.com/deepmipt/ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_natasha(text: str) -> str:\n",
    "    pass\n",
    "\n",
    "def preprocess_with_deepmipt(text: str) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Буду использовать два готовых экстрактора для имён и адресов, а для дат соберу экстрактор сама и дополню правила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Это самые базовые правила для извлечения дат, из них я соберу собственный экстрактор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy import Parser, rule, and_, not_\n",
    "from yargy.interpretation import fact, attribute\n",
    "from yargy.predicates import gram, dictionary, gte, lte, eq\n",
    "from yargy.relations import gnc_relation\n",
    "from yargy.pipelines import morph_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = fact(\n",
    "    'Date',\n",
    "    ['year', 'month', 'day']\n",
    ")\n",
    "\n",
    "class Date(Date):\n",
    "    @property\n",
    "    def obj(self):\n",
    "        from natasha import obj\n",
    "        return obj.Date(self.year, self.month, self.day)\n",
    "\n",
    "\n",
    "MONTHS = {\n",
    "    'январь',\n",
    "    'февраль',\n",
    "    'март',\n",
    "    'апрель',\n",
    "    'мая',\n",
    "    'июнь',\n",
    "    'июль',\n",
    "    'август',\n",
    "    'сентябрь',\n",
    "    'октябрь',\n",
    "    'ноябрь',\n",
    "    'декабрь'\n",
    "}\n",
    "\n",
    "\n",
    "MONTH_NAME = dictionary(MONTHS)\n",
    "DAY = and_(\n",
    "    gte(1),\n",
    "    lte(31)\n",
    ")\n",
    "YEAR = and_(\n",
    "    gte(1900),\n",
    "    lte(2100)\n",
    ")\n",
    "DATE = rule(\n",
    "    DAY.interpretation(\n",
    "        Date.day\n",
    "    ),\n",
    "    MONTH_NAME.interpretation(\n",
    "        Date.month\n",
    "    ),\n",
    "    YEAR.interpretation(\n",
    "        Date.year\n",
    "    ).optional()\n",
    ").interpretation(\n",
    "    Date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha.extractors import Extractor\n",
    "class DatesExtractor(Extractor):\n",
    "    def __init__(self, morph):\n",
    "        Extractor.__init__(self, DATE, morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import NamesExtractor, AddrExtractor\n",
    "from natasha import MorphVocab\n",
    "morph_vocab = MorphVocab()\n",
    "name_extractor = NamesExtractor(morph_vocab)\n",
    "address_extractor = AddrExtractor(morph_vocab)\n",
    "date_extractor = DatesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_natasha(text: str) -> str:\n",
    "    ner_spans = []\n",
    "    persons = [x for x in name_extractor(text)]\n",
    "    places = [x for x in address_extractor(text)]\n",
    "    dates = [x for x in date_extractor(text)]\n",
    "    ner_spans.extend(dates)\n",
    "    ner_spans.extend(persons)\n",
    "    ner_spans.extend(places)\n",
    "    for entity in ner_spans:\n",
    "        start, end = entity.start, entity.stop\n",
    "        text_before_ent = text[:start]\n",
    "        text_after_ent = text[end:]\n",
    "        substitute_text = ' ' * (end - start)\n",
    "        text = f'{text_before_ent}{substitute_text}{text_after_ent}'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Попробую удаление NER на тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 4.05 ms, total: 141 ms\n",
      "Wall time: 150 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Я,                      прибыл                     , Турция. Мне       справка?'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_with_natasha('Я, Иванов Иван Иванович прибыл в Россию из Стамбула, Турция. Мне нужна справка?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "В результате есть ложно положительный спан \"нужна\" и ложно отрицательный \"Турция\". \n",
    "В целом, ок и это без препроцессинга с моей стороны!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Попробую реализовать удаление NER через deepmipt, но так deeppavlov это то же самое, то буду использовать его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Сейчас будет много ворнингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-21 16:52:28.846 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/elizavetaersova/.deeppavlov/models/ner_rus/word.dict]\n",
      "2020-10-21 16:52:28.914 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/elizavetaersova/.deeppavlov/models/ner_rus/tag.dict]\n",
      "2020-10-21 16:52:28.918 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/elizavetaersova/.deeppavlov/models/ner_rus/char.dict]\n",
      "2020-10-21 16:52:28.922 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 53: [loading fastText embeddings from `/Users/elizavetaersova/.deeppavlov/downloads/embeddings/lenta_lower_100.bin`]\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "2020-10-21 16:52:36.551 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2020-10-21 16:52:36.757 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
      "2020-10-21 16:52:39.606 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /Users/elizavetaersova/.deeppavlov/models/ner_rus/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/elizavetaersova/.deeppavlov/models/ner_rus/model\n",
      "CPU times: user 5.72 s, sys: 2.98 s, total: 8.7 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from deeppavlov import configs, build_model\n",
    "\n",
    "ner_model = build_model(configs.ner.ner_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_deepmipt(text: str) -> str:\n",
    "    anno = ner_model([text])\n",
    "    tokens = anno[0][0]\n",
    "    tags = anno[1][0]\n",
    "    clean_tokens = []\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        if tag == 'O':\n",
    "            clean_tokens.append(token)\n",
    "    clean_text = ' '.join(clean_tokens)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 ms, sys: 2.87 ms, total: 20.7 ms\n",
      "Wall time: 20.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Я , прибыл в из , . Мне нужна справка ?'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_with_deepmipt('Я, Иванов Иван Иванович прибыл в Россию из Стамбула, Турция. Мне нужна справка?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Идеальная работа и быстро!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "На предыдущем занятии вы реализовывали функции поиска ближайших ответов на запросы через TF-IDF и BM25. \n",
    "Сравните качество нахождения верного ответа для обоих методов в трех случаях:\n",
    "- с функцией ```preprocess_with_natasha```\n",
    "- с функцией ```preprocess_with_deepmipt```\n",
    "- без препроцессинга\n",
    "\n",
    "Для измерения качества используйте метрику accuracy. Считаем, что ответ верный, если он входит в топ-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Я понимаю \"без препроцессинга\" как \"без удаления NE\".\n",
    "Для эксперимента возьму сырые тексты, обработаю либо просто препроцессингом, либо препроцессингом и удалением NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^а-яё]', ' ', text)\n",
    "    text = [token for token in text.split() if token not in russian_stopwords]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')  \n",
    "X_train =  X_train.rename(columns={'Unnamed: 0': 'question_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 53s, sys: 15.2 s, total: 9min 9s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train['clean_text'] = X_train.text.apply(lambda x: str(preprocess(x)))\n",
    "X_train['Natasha_NER_removal'] = X_train.text.apply(lambda x: str(preprocess(preprocess_with_natasha(x))))\n",
    "X_train['Deepmipt_NER_removal'] = X_train.text.apply(lambda x: str(preprocess(preprocess_with_deepmipt(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Natasha_NER_removal</th>\n",
       "      <th>Deepmipt_NER_removal</th>\n",
       "      <th>answer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354</td>\n",
       "      <td>Добрый день!        \\n        \\nПрошу описать ...</td>\n",
       "      <td>добрый день прошу описать порядок действий тре...</td>\n",
       "      <td>прошу описать порядок действий требуемые докум...</td>\n",
       "      <td>добрый день прошу описать порядок действий тре...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2114</td>\n",
       "      <td>\\nДобрый день!\\n1.Нужно ли сотруднику прибывше...</td>\n",
       "      <td>добрый день нужно сотруднику прибывшему г тюме...</td>\n",
       "      <td>сотруднику прибывшему самоизоляции дней сдават...</td>\n",
       "      <td>добрый день нужно сотруднику прибывшему г само...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>450</td>\n",
       "      <td>Какие ограничения действуют при поездке в Абха...</td>\n",
       "      <td>какие ограничения действуют поездке абхазию де...</td>\n",
       "      <td>ограничения действуют поездке абхазию карантин...</td>\n",
       "      <td>какие ограничения действуют поездке действуют ...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1537</td>\n",
       "      <td>Здравствуйте, подскажите пожалуйста, где можно...</td>\n",
       "      <td>здравствуйте подскажите пожалуйста пройти тест...</td>\n",
       "      <td>подскажите пожалуйста пройти определение пропа...</td>\n",
       "      <td>здравствуйте подскажите пожалуйста пройти тест...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296</td>\n",
       "      <td>Добрый день! Подскажите,если я (гражданин Р.Ф....</td>\n",
       "      <td>добрый день подскажите гражданин р ф поеду отп...</td>\n",
       "      <td>подскажите гражданин отпкус наземным транспорт...</td>\n",
       "      <td>добрый день подскажите гражданин р ф поеду отп...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                                               text  \\\n",
       "0          354  Добрый день!        \\n        \\nПрошу описать ...   \n",
       "1         2114  \\nДобрый день!\\n1.Нужно ли сотруднику прибывше...   \n",
       "2          450  Какие ограничения действуют при поездке в Абха...   \n",
       "3         1537  Здравствуйте, подскажите пожалуйста, где можно...   \n",
       "4          296  Добрый день! Подскажите,если я (гражданин Р.Ф....   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  добрый день прошу описать порядок действий тре...   \n",
       "1  добрый день нужно сотруднику прибывшему г тюме...   \n",
       "2  какие ограничения действуют поездке абхазию де...   \n",
       "3  здравствуйте подскажите пожалуйста пройти тест...   \n",
       "4  добрый день подскажите гражданин р ф поеду отп...   \n",
       "\n",
       "                                 Natasha_NER_removal  \\\n",
       "0  прошу описать порядок действий требуемые докум...   \n",
       "1  сотруднику прибывшему самоизоляции дней сдават...   \n",
       "2  ограничения действуют поездке абхазию карантин...   \n",
       "3  подскажите пожалуйста пройти определение пропа...   \n",
       "4  подскажите гражданин отпкус наземным транспорт...   \n",
       "\n",
       "                                Deepmipt_NER_removal  answer_id  \n",
       "0  добрый день прошу описать порядок действий тре...        308  \n",
       "1  добрый день нужно сотруднику прибывшему г само...        308  \n",
       "2  какие ограничения действуют поездке действуют ...        308  \n",
       "3  здравствуйте подскажите пожалуйста пройти тест...        135  \n",
       "4  добрый день подскажите гражданин р ф поеду отп...        308  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 ms, sys: 2.96 ms, total: 56.9 ms\n",
      "Wall time: 60.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_basic = X_train.clean_text.tolist()\n",
    "tokenized_basic_corpus = [doc.split() for doc in corpus_basic]\n",
    "bm25_basic = BM25Okapi(tokenized_basic_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.9 ms, sys: 1.54 ms, total: 36.4 ms\n",
      "Wall time: 42.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_natasha = X_train.Natasha_NER_removal.tolist()\n",
    "tokenized_corpus_natasha = [doc.split() for doc in corpus_natasha]\n",
    "bm25_natasha = BM25Okapi(tokenized_corpus_natasha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.8 ms, sys: 2.67 ms, total: 54.5 ms\n",
      "Wall time: 66.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_deepmipt = X_train.Deepmipt_NER_removal.tolist()\n",
    "tokenized_corpus_deepmipt = [doc.split() for doc in corpus_deepmipt]\n",
    "bm25_deepmipt = BM25Okapi(tokenized_corpus_deepmipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search_basic(query):\n",
    "    query = preprocess(query)\n",
    "    tokenized_query = query.split()\n",
    "    answer_text = bm25_basic.get_top_n(tokenized_query, corpus_basic, n=1)\n",
    "    answer_id = X_train[X_train['clean_text'] == answer_text[0]].iloc[0]['answer_id']\n",
    "    return answer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search_natasha_ner(query):\n",
    "    query = preprocess(preprocess_with_natasha(query))\n",
    "    tokenized_query = query.split()\n",
    "    answer_text = bm25_natasha.get_top_n(tokenized_query, corpus_natasha, n=1)\n",
    "    answer_id = X_train[X_train['Natasha_NER_removal'] == answer_text[0]].iloc[0]['answer_id']\n",
    "    return answer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search_deepmipt_ner(query):\n",
    "    query = preprocess(preprocess_with_deepmipt(query))\n",
    "    tokenized_query = query.split()\n",
    "    answer_text = bm25_deepmipt.get_top_n(tokenized_query, corpus_deepmipt, n=1)\n",
    "    answer_id = X_train[X_train['Deepmipt_NER_removal'] == answer_text[0]].iloc[0]['answer_id']\n",
    "    return answer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "X_test = X_test.join(y_test, lsuffix='_caller', rsuffix='_actions')\n",
    "X_test = X_test.drop(columns=['Unnamed: 0_caller', 'Unnamed: 0_actions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Добрый вечер! Моя мама сдавала анализ на ПЦР 5...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Здравствуйте для прохождения на тест карновиру...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Добрый день.\\nВ Новосибирске были сняты ограни...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nЗдравствуйте! Я прибыл из Финляндии в Карели...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Здравствуйте. Я гражданка Российской Федерации...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Здравствуйте! В магазине Пятёрочка (г. Калуга,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Где сдать экспресс-тест на коронавирус в Сургу...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>У меня большая просьба ответьте на мой вопрос ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Здравствуйте! Подскажите, пожалуйста, в какой ...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Добрый день. Мы с семьёй планируем поехать в А...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  answer_id\n",
       "0    Добрый вечер! Моя мама сдавала анализ на ПЦР 5...          6\n",
       "1    Здравствуйте для прохождения на тест карновиру...        308\n",
       "2    Добрый день.\\nВ Новосибирске были сняты ограни...         37\n",
       "3    \\nЗдравствуйте! Я прибыл из Финляндии в Карели...        308\n",
       "4    Здравствуйте. Я гражданка Российской Федерации...        308\n",
       "..                                                 ...        ...\n",
       "571  Здравствуйте! В магазине Пятёрочка (г. Калуга,...          1\n",
       "572  Где сдать экспресс-тест на коронавирус в Сургу...        135\n",
       "573  У меня большая просьба ответьте на мой вопрос ...         12\n",
       "574  Здравствуйте! Подскажите, пожалуйста, в какой ...         37\n",
       "575  Добрый день. Мы с семьёй планируем поехать в А...        308\n",
       "\n",
       "[576 rows x 2 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 35s, sys: 6.5 s, total: 4min 42s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test['clean_text'] = X_test.text.apply(lambda x: str(preprocess(x)))\n",
    "X_test['Natasha_NER_removal'] = X_test.text.apply(lambda x: str(preprocess(preprocess_with_natasha(x))))\n",
    "X_test['Deepmipt_NER_removal'] = X_test.text.apply(lambda x: str(preprocess(preprocess_with_deepmipt(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test.answer_id.tolist()\n",
    "X_test_basic = X_test.clean_text.tolist()\n",
    "X_test_ner_natasha = X_test.Natasha_NER_removal.tolist()\n",
    "X_test_ner_deepmipt = X_test.Deepmipt_NER_removal.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Без удаления NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6319444444444444\n",
      "CPU times: user 10.6 s, sys: 76.5 ms, total: 10.6 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_corr = 0\n",
    "n_queries = len(X_test_basic)\n",
    "for query, answer in zip(X_test_basic, y_test):\n",
    "    pred_answer = bm25_search_basic(query)\n",
    "    real_answer = answer\n",
    "    if pred_answer == real_answer:\n",
    "        n_corr += 1\n",
    "print(f'Accuracy {n_corr/n_queries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "С удалением NE Наташей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6197916666666666\n",
      "CPU times: user 1min 19s, sys: 658 ms, total: 1min 20s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_corr = 0\n",
    "n_queries = len(X_test_ner_natasha)\n",
    "for query, answer in zip(X_test_ner_natasha, y_test):\n",
    "    pred_answer = bm25_search_natasha_ner(query)\n",
    "    real_answer = answer\n",
    "    if pred_answer == real_answer:\n",
    "        n_corr += 1\n",
    "print(f'Accuracy {n_corr/n_queries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "С удалением NE Deepmipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6076388888888888\n",
      "CPU times: user 27.9 s, sys: 2.24 s, total: 30.1 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_corr = 0\n",
    "n_queries = len(X_test_ner_deepmipt)\n",
    "for query, answer in zip(X_test_ner_deepmipt, y_test):\n",
    "    pred_answer = bm25_search_deepmipt_ner(query)\n",
    "    real_answer = answer\n",
    "    if pred_answer == real_answer:\n",
    "        n_corr += 1\n",
    "print(f'Accuracy {n_corr/n_queries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Удаление NE не улучшает качество поиска "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 3__:    \n",
    "Улучшить правила в natasha. Написать правила, которые ловят даты в следующих примерах и пересчитать статистику из Задачи 2:\n",
    "- Уехал 8-9 ноября в Сочи\n",
    "- Уезжаю 5 числа                           \n",
    "- 20го сентября заболел\n",
    "\n",
    "Пример можно посмотреть тут: https://github.com/natasha/yargy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Дополню текущие правила DatesExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = fact(\n",
    "    'Date',\n",
    "    ['year', 'month', 'day']\n",
    ")\n",
    "\n",
    "class Date(Date):\n",
    "    @property\n",
    "    def obj(self):\n",
    "        from natasha import obj\n",
    "        return obj.Date(self.year, self.month, self.day)\n",
    "\n",
    "\n",
    "MONTHS = {\n",
    "    'январь',\n",
    "    'февраль',\n",
    "    'март',\n",
    "    'апрель',\n",
    "    'мая',\n",
    "    'июнь',\n",
    "    'июль',\n",
    "    'август',\n",
    "    'сентябрь',\n",
    "    'октябрь',\n",
    "    'ноябрь',\n",
    "    'декабрь',\n",
    "    'число'\n",
    "}\n",
    "\n",
    "\n",
    "MONTH_NAME = dictionary(MONTHS)\n",
    "\n",
    "\n",
    "DAY = and_(\n",
    "    gte(1),\n",
    "    lte(31)\n",
    ")\n",
    "\n",
    "\n",
    "YEAR = and_(\n",
    "    gte(1900),\n",
    "    lte(2100)\n",
    ")\n",
    "\n",
    "\n",
    "IMP_DATE = rule(\n",
    "    DAY.interpretation(Date.day),\n",
    "    eq('го').optional(),\n",
    "    eq('-').optional(),\n",
    "    DAY.optional().repeatable().interpretation(Date.day),\n",
    "    MONTH_NAME.interpretation(Date.month),\n",
    "    YEAR.interpretation(Date.year).optional()\n",
    ").interpretation(\n",
    "    Date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Переопределю экстрактор, чтобы использовать в функции новые правила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha.extractors import Extractor\n",
    "class ImpDatesExtractor(Extractor):\n",
    "    def __init__(self, morph):\n",
    "        Extractor.__init__(self, IMP_DATE, morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_extractor = ImpDatesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 ms, sys: 2.42 ms, total: 31.4 ms\n",
      "Wall time: 41.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                 '"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_with_natasha('8-9 ноября в Сочи')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 ms, sys: 356 µs, total: 14.5 ms\n",
      "Wall time: 15.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Уезжаю        '"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_with_natasha('Уезжаю 5 числа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 ms, sys: 1.17 ms, total: 28.5 ms\n",
      "Wall time: 33.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              заболел'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_with_natasha('20го сентября заболел')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Во всех случаях новые правила справляются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Пересчитаю статистику с использованием новых правил в предобработке запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6197916666666666\n",
      "CPU times: user 1min 20s, sys: 692 ms, total: 1min 20s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_corr = 0\n",
    "n_queries = len(X_test_ner_natasha)\n",
    "for query, answer in zip(X_test_ner_natasha, y_test):\n",
    "    pred_answer = bm25_search_natasha_ner(query)\n",
    "    real_answer = answer\n",
    "    if pred_answer == real_answer:\n",
    "        n_corr += 1\n",
    "print(f'Accuracy {n_corr/n_queries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Качество не изменилось"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
