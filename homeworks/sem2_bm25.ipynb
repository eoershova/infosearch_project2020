{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    " \n",
    "# инициализируем\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# составляем корпус документов\n",
    "corpus = [\n",
    "  'слово1 слово2 слово3',\n",
    "  'слово2 слово3',\n",
    "  'слово1 слово2 слово1',\n",
    "  'слово4'\n",
    "]\n",
    "\n",
    "# считаем\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "# получится следующая структура:\n",
    "#        |  слово1  |  слово2  |  слово3  |  слово4\n",
    "# текст1 |   0.6    |    0.5   |   0.6    |    0\n",
    "# текст2 |   0      |    0.6   |   0.8    |    0\n",
    "# текст3 |   0.9    |    0.4   |   0      |    0\n",
    "# текст4 |   0      |    0     |   0      |    1\n",
    " \n",
    "# чтобы получить сгенерированный словарь, из приведенной структуры TfidfVectorizer\n",
    "# порядок совпадает с матрицей\n",
    "vectorizer.get_feature_names()  # ['слово1', 'слово2', 'слово3', 'слово4']\n",
    " \n",
    "# чтобы узнать индекс токена в словаре\n",
    "vectorizer.vocabulary_.get('слово3') # вернет 2\n",
    " \n",
    "# показать матрицу\n",
    "X.toarray()\n",
    " \n",
    "# теперь можно быстро подсчитать вектор для нового документа\n",
    "new_doc = vectorizer.transform(['слово1 слово4 слово4']).toarray()  # результат [[0.36673901, 0, 0, 0.93032387]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def bm25(corpus, document, query):\n",
    "    l_d = len(document.split())\n",
    "    avgdl = get_av_len_doc(corpus)\n",
    "    bm25_score = 0\n",
    "    for word in query.split():\n",
    "        idf = get_idf(word, corpus)\n",
    "        tf = get_tf(word, document)\n",
    "        bm25_score += idf * ((tf * (k + 1) ) / (tf + k * (1 - b + b * l_d / avgdl)))\n",
    "    return bm25_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_av_len_doc(corpus):\n",
    "    n_words = 0\n",
    "    n_docs = 0\n",
    "    for doc in corpus:\n",
    "        n_words += len(doc.split())\n",
    "        n_docs += 1\n",
    "    avgdl = n_words/n_docs\n",
    "    return avgdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(word, corpus):\n",
    "    N = len(corpus)\n",
    "    nqi = 0\n",
    "    for doc in corpus:\n",
    "        if word in doc:\n",
    "            nqi += 1\n",
    "    if nqi == 0:\n",
    "        nqi = 0.00000001\n",
    "    idf = log(N - nqi + 0.5 / nqi + 0.5 )\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(word, document):\n",
    "    tf = 0\n",
    "    for token in document.split():\n",
    "        if token == word:\n",
    "            tf += 1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'турция',\n",
    "    'нужна справка срочно'\n",
    "]\n",
    "document1 = 'нужна справка срочно'\n",
    "document2 = 'турция'\n",
    "query = 'быстрая справка'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5545177444479562"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25(corpus, document1, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25(corpus, document2, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Действительно, метрика находит ближайший документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "В такой реализации метрика максимально наглядна, но и максимально неоптимальна,\n",
    "поэтому в заданиях я буду использовать реализацию из библиотеки rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Реализуйте поиск с метрикой *TF-IDF* через умножение матрицы на вектор.\n",
    "Что должно быть в реализации:\n",
    "- проиндексированная база, где каждый документ представлен в виде вектора TF-IDF\n",
    "- функция перевода входяшего запроса в вектор по метрике TF-IDF\n",
    "- ранжирование докуменов по близости к запросу по убыванию\n",
    "\n",
    "В качестве корпуса возьмите корпус вопросов в РПН по Covid2019. Он состоит из:\n",
    "> файл **answers_base.xlsx** - база ответов, у каждого ответа есть его номер, тематика и примеры вопросов, которые могут быть заданы к этому ответу. Сейчас проиндексировать надо именно примеры вопросов в качестве документов базы. Понимаете почему?\n",
    "\n",
    "> файл **queries_base.xlsx** - вопросы юзеров, к каждому из которых проставлен номер верного ответа из базы. Разделите эти вопросы в пропорции 70/30 на обучающую (проиндексированную как база) и тестовую (как запросы) выборки. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Загружу всё необходимое: стопслова и предобработанные запросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^а-яё]', ' ', text)\n",
    "    text = [token for token in text.split() if token not in russian_stopwords]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_base = pd.read_csv('X_train_NER_preproc.csv')\n",
    "tokens_corpus = queries_base.clean_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Индексация базы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_base_indexing_tfidf():\n",
    "    global tfidf_matrix, vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_corpus = tokens_corpus\n",
    "    tfidf = vectorizer.fit_transform(tfidf_corpus)\n",
    "    tfidf_matrix = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 119 ms, sys: 29.9 ms, total: 149 ms\n",
      "Wall time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query_base_indexing_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Поиск по базе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_search(query):\n",
    "    query = preprocess(query)\n",
    "    query_tdidf_vector = vectorizer.transform([query]).toarray()\n",
    "    cosine_similarities = linear_kernel(query_tdidf_vector, tfidf_matrix).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "    answer_doc = related_docs_indices[0]\n",
    "    answer_id = queries_base['answer_id'][answer_doc]\n",
    "    return answer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.4 ms, sys: 15.6 ms, total: 55.9 ms\n",
      "Wall time: 46.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_search('я вернулся из стамбула, мне нужно сдать анализ на коронавирус?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ответ верный, поиск быстрый"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "Аналогичная задаче1 с другой метрикой \n",
    "\n",
    "Реализуйте поиск с метрикой *BM25* через умножение матрицы на вектор. Что должно быть в реализации:\n",
    "\n",
    "- проиндексированная база, где каждый документ представлен в виде вектора BM25\n",
    "- функция перевода входяшего запроса в вектор по метрике BM25\n",
    "- ранжирование докуменов по близости к запросу по убыванию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Индексация базы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_base_indexing_bm25():\n",
    "    global bm25\n",
    "    tokenized_corpus = [doc.split() for doc in tokens_corpus]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.5 ms, sys: 6.17 ms, total: 59.7 ms\n",
      "Wall time: 60.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query_base_indexing_bm25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Поиск по базе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query):\n",
    "    query = preprocess(query)\n",
    "    tokenized_query = query.split()\n",
    "    answer_text = bm25.get_top_n(tokenized_query, tokens_corpus, n=1)\n",
    "    answer_id = queries_base[queries_base['clean_text'] == answer_text[0]].iloc[0]['answer_id']\n",
    "    return answer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.2 ms, sys: 3.3 ms, total: 12.5 ms\n",
      "Wall time: 16.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bm25_search('я вернулся из стамбула, мне нужно сдать анализ на коронавирус?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ответ верный, поиск ещё быстрее!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
